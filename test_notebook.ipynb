{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Lecture 7 is key to my problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/data/data_clean\")\n",
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"Article text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = (\n",
    "    \"Tiger Woods: Is this the end of his era? - CNN,Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. \",\n",
    "    \"golf, Tiger Woods: Is this the end of his era? - CNN,Is this the end of the Tiger Woods era?,This story was excerpted from the November 23 edition of CNN's Meanwhile in America, the daily email about US politics for global readers. Click here to read past editions and subscribe. (CNN)Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. Woods, who is recuperating from devastating leg injuries from a car crash, told Golf Digest he would have to be more selective about competition from now on. \"\n",
    "    \"I think something that is realistic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(sequence_to_classify, candidate_labels, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasoning for new model\n",
    "\n",
    "https://huggingface.co/valhalla/distilbart-mnli-12-1 has 90% of the facebook/bart-large-mnli model's performance but is way faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/data/data_clean\")\n",
    "model_name = \"facebook/bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_2 = \"valhalla/distilbart-mnli-12-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"valhalla/distilbart-mnli-12-1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16,  # adjust batch size\n",
    "    )\n",
    "\n",
    "\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=True, truncation=True, max_length=42)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "from transformers import AutoTokenizer, AutoModel, , AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"facebook/bart-large-mnli\"\n",
    "    tokenizer = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16, # adjust batch size\n",
    "    )\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function\n",
    "df_encoded = zero_shot_labelling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name_2,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = (\n",
    "    \"Tiger Woods: Is this the end of his era? - CNN,Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. \",\n",
    "    \"golf, Tiger Woods: Is this the end of his era? - CNN,Is this the end of the Tiger Woods era?,This story was excerpted from the November 23 edition of CNN's Meanwhile in America, the daily email about US politics for global readers. Click here to read past editions and subscribe. (CNN)Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. Woods, who is recuperating from devastating leg injuries from a car crash, told Golf Digest he would have to be more selective about competition from now on. \"\n",
    "    \"I think something that is realistic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df_try = df\n",
    "\n",
    "\n",
    "def pd_to_dataset(data):\n",
    "    data = Dataset.from_pandas(data)\n",
    "    dataset_dict = DatasetDict({\"my_dataset\": data})\n",
    "    return dataset_dict[\"my_dataset\"]\n",
    "\n",
    "\n",
    "df_encoded = zero_shot_labelling(df_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(df_encoded[\"Description\"], candidate_labels, tokenizer=_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to speed it up:\n",
    "- Batch size of 8\n",
    "- padding can be reduced to speed up computation\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "delete_strategy = scan_cache_dir().delete_revisions(\n",
    "    \"81fd1d6e7847c99f5862c9fb81387956d99ec7aa\"\n",
    "    \"e2983b237dccf3ab4937c97fa717319a9ca1a96d\",\n",
    "    \"6c0e6080953db56375760c0471a8c5f2929baf11\",\n",
    ")\n",
    "print(\"Will free \" + delete_strategy.expected_freed_size_str)\n",
    "\n",
    "\n",
    "delete_strategy.execute()\n",
    "\n",
    "# Specify the directory you want to clear the cache for\n",
    "cache_directory = \"/path/to/your/cache/directory\"\n",
    "\n",
    "# Use scan_cache_dir to clear the cache in the specified directory\n",
    "scan_cache_dir(cache_directory).clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuer try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "df = load_from_disk(\"bld/python/data/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = zero_shot_labelling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"valhalla/distilbart-mnli-12-1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16,  # adjust batch size\n",
    "    )\n",
    "\n",
    "\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=True, truncation=True, max_length=42)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_2 = \"valhalla/distilbart-mnli-12-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name_2,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(df[\"Description\"], candidate_labels, tokenizer=_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "df = load_from_disk(\"bld/python/data/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100_entries = df.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = zero_shot_classifier(first_100_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def zero_shot_classifier(data):\n",
    "    \"\"\"Classify the zero-shot data to receive the labels.\"\"\"\n",
    "    data = _zero_shot_labelling(data)\n",
    "    model_name = \"valhalla/distilbart-mnli-12-6\"\n",
    "    labels = [\"labor supply\", \"labor demand\", \"government intervention\"]\n",
    "    classifier = pipeline(  # second last\n",
    "        \"zero-shot-classification\",\n",
    "        model=model_name,\n",
    "        multi_label=True,\n",
    "        device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    "    )\n",
    "    return classifier(  # last\n",
    "        data[\"Description\"],\n",
    "        labels,\n",
    "        tokenizer=_tokenize,\n",
    "    )\n",
    "\n",
    "\n",
    "def _zero_shot_labelling(data):\n",
    "    \"\"\"Load the model for zero-shot classification and apply on the data.\"\"\"\n",
    "    model_name = \"valhalla/distilbart-mnli-12-6\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=8,\n",
    "    )\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    \"\"\"Define the tokenizer.\"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"Description\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For reading to know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the previous\n",
    "select_random_entries(df, num_entries=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- does the probability of the model suits or should I transform to 0 and 1\n",
    "- test and training separation\n",
    "- model selection\n",
    "- put the head on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "df = load_from_disk(r\"bld\\python\\labelled\\data_labelled_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset_dict_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save_to_disk(\"bld/python/TrainTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "def _split_dataset(df):\n",
    "    # Shuffle the dataset to ensure randomization\n",
    "    df = df.shuffle(seed=42)\n",
    "\n",
    "    # Calculate the split sizes\n",
    "    total_size = len(df)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = int(0.1 * total_size)\n",
    "    total_size - train_size - val_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset = datasets.Dataset.from_dict(df[:train_size])\n",
    "    val_dataset = datasets.Dataset.from_dict(df[train_size : train_size + val_size])\n",
    "    test_dataset = datasets.Dataset.from_dict(df[train_size + val_size :])\n",
    "\n",
    "    # Rename columns if needed\n",
    "    train_dataset = train_dataset.rename_column(\"sequence\", \"text\")\n",
    "    val_dataset = val_dataset.rename_column(\"sequence\", \"text\")\n",
    "    test_dataset = test_dataset.rename_column(\"sequence\", \"text\")\n",
    "\n",
    "    # You may need to specify the 'labels' column name if it's different\n",
    "    # Assuming it's 'labels' in your dataset, rename it to 'label'\n",
    "    train_dataset = train_dataset.rename_column(\"labels\", \"label\")\n",
    "    val_dataset = val_dataset.rename_column(\"labels\", \"label\")\n",
    "    test_dataset = test_dataset.rename_column(\"labels\", \"label\")\n",
    "\n",
    "    return {\n",
    "        \"train_dataset\": train_dataset,\n",
    "        \"val_dataset\": val_dataset,\n",
    "        \"test_dataset\": test_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataset_dict_2(df):\n",
    "    # Split the dataset using the split_dataset function\n",
    "    split_data = _split_dataset(df)\n",
    "\n",
    "    # Create a DatasetDict containing train, validation, and test datasets\n",
    "    return datasets.DatasetDict(split_data)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = Your existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train_dataset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_ckpt,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[\"train_dataset\"].column_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[\"train_dataset\"].column_names\n",
    "cols.remove(\"scores\")\n",
    "df_enc = df.map(tokenize_and_encode, batched=True, remove_columns=cols)\n",
    "df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores and labels are badly named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast label IDs to floats\n",
    "import torch\n",
    "\n",
    "df_enc.set_format(\"torch\")\n",
    "df_enc = df_enc.map(\n",
    "    lambda x: {\"float_labels\": x[\"scores\"].to(torch.float)},\n",
    "    remove_columns=[\"scores\"],\n",
    ").rename_column(\"float_labels\", \"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=1,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\".\", num_train_epochs=1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=df_enc[\"train_dataset\"],\n",
    "    eval_dataset=df_enc[\"val_dataset\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc[\"train_dataset\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input lists to tensors\n",
    "input_ids = torch.tensor(df_enc[\"train_dataset\"][\"input_ids\"])\n",
    "attention_mask = torch.tensor(df_enc[\"train_dataset\"][\"attention_mask\"])\n",
    "\n",
    "# Forward pass through the model to get logits\n",
    "logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(\n",
    "    logits.logits,\n",
    "    scores.float(),\n",
    ")  # Use logits.logits to access the raw logits\n",
    "\n",
    "# Apply a threshold to the logits to determine class predictions (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "predictions = (torch.sigmoid(logits.logits) >= threshold).int()\n",
    "\n",
    "# 'predictions' now contains the predicted classes for each ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=df[\"train_dataset\"],\n",
    "    eval_dataset=df[\"val_dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additionall model/CURRENT ISSUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train_dataset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import DatasetDict\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# Initialize a pre-trained tokenizer and model\n",
    "model_name = \"bert-base-uncased\"  # You can change this to your desired model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "\n",
    "# Assuming df_enc contains the dataset in the correct format\n",
    "# df_enc should look like this:\n",
    "# DatasetDict({\n",
    "#     train_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "#     val_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "#     test_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "\n",
    "# Define the loss function for multi-label classification (e.g., BCEWithLogitsLoss)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Convert text data to input tensors using the tokenizer\n",
    "df[\"train_dataset\"] = tokenizer(\n",
    "    df[\"train_dataset\"][\"text\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "df[\"val_dataset\"] = tokenizer(\n",
    "    df[\"val_dataset\"][\"text\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# Forward pass through the model to get logits\n",
    "input_ids = df[\"train_dataset\"][\"input_ids\"]\n",
    "attention_mask = df[\"train_dataset\"][\"attention_mask\"]\n",
    "logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Assuming 'scores' is already in the correct format\n",
    "scores = torch.tensor(df[\"train_dataset\"][\"scores\"], dtype=torch.float32)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(logits.logits, scores)\n",
    "\n",
    "# Define your training arguments and trainer and train the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,  # Adjust as needed\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,  # Adjust as needed\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=None,  # You can specify a data collator if needed\n",
    "    train_dataset=df_enc[\"train_dataset\"],  # Use your train_dataset here\n",
    "    eval_dataset=df_enc[\"val_dataset\"],  # Use your val_dataset here\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "labels = df[\"train_dataset\"][\"label\"]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"bert-base-cased\"\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(df[\"train_dataset\"][\"scores\"][0]),\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Function to preprocess the dataset and return it in the required format\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the text and encode it into input features\n",
    "    inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Convert scores to a tensor (assuming scores are already in the correct format)\n",
    "    scores = torch.tensor(examples[\"scores\"], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"labels\": scores,\n",
    "    }\n",
    "\n",
    "\n",
    "# Preprocess the datasets\n",
    "train_dataset = df[\"train_dataset\"].map(preprocess_function)\n",
    "val_dataset = df[\"val_dataset\"].map(preprocess_function)\n",
    "test_dataset = df[\"test_dataset\"].map(preprocess_function)\n",
    "\n",
    "# Define your training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, p.label_ids\n",
    "    predictions = (predictions > 0).astype(int)  # Convert logits to binary predictions\n",
    "    f1 = f1_score(labels, predictions, average=\"micro\")\n",
    "    precision = precision_score(labels, predictions, average=\"micro\")\n",
    "    recall = recall_score(labels, predictions, average=\"micro\")\n",
    "    return {\"f1_micro\": f1, \"precision_micro\": precision, \"recall_micro\": recall}\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df[\"train_dataset\"].select_columns([\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess because values are apparently string and not int\n",
    "\n",
    "model_output = pd.DataFrame(classifier(df[\"val_dataset\"][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "\n",
    "def tokenize_data(df):\n",
    "    return tokenizer(\n",
    "        df[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "df_encoded = df.map(tokenize, batched=True, batch_size=None)\n",
    "df_encoded.set_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "df_encoded.set_format(\"torch\")\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 6\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\", num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=df_encoded[\"train_dataset\"],\n",
    "    eval_dataset=df_encoded[\"val_dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR FIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def authenticate_to_kaggle():\n",
    "    \"\"\"Authenticate to Kaggle.\"\"\"\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = authenticate_to_kaggle()\n",
    "dataset = \"hadasu92/cnn-articles-after-basic-cleaning\"\n",
    "api.dataset_download_files(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "kaggle.api.dataset_download_files(\n",
    "    dataset,\n",
    "    path=\"./bld/python/data\",\n",
    "    unzip=True,\n",
    "    quiet=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(api.dataset_download_files(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_load_data_python(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"bld/python/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "\n",
    "def task_load_data_python(path):\n",
    "    \"\"\"Clean the data (Python version).\n",
    "\n",
    "    Download needs up to 5 minutes. Is this due to internet or coding issue?\n",
    "\n",
    "    \"\"\"\n",
    "    api = authenticate_to_kaggle()\n",
    "    dataset = \"hadasu92/cnn-articles-after-basic-cleaning\"\n",
    "    api.dataset_download_files(dataset)\n",
    "    with zipfile.ZipFile(\"cnn-articles-after-basic-cleaning.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depends_on = r\"src\\EN\\data_management\\data_info.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = r\"bld\\python\\data\\CNN_Articels_clean\\CNN_Articels_clean.csv\"\n",
    "df_2 = r\"bld\\python\\data\\CNN_Articels_clean_2\\CNN_Articels_clean.csv\"\n",
    "\n",
    "\n",
    "df_1 = pd.read_csv(df_1)  # need to delete cache here\n",
    "df_2 = pd.read_csv(df_2)\n",
    "data = clean_data(df_1, df_2)\n",
    "data.save_to_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "def clean_data(data_1, data_2):\n",
    "    \"\"\"Clean data set.\n",
    "\n",
    "    Information on data columns is stored in ``data_management/data_info.yaml``.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data set.\n",
    "        data_info (dict): Information on data set stored in data_info.yaml. The\n",
    "            following keys can be accessed:\n",
    "            - 'Index': Running number\n",
    "            - 'Author': Author who wrote Article\n",
    "            - 'Date published': Publishing date of Article\n",
    "            - 'Category': Higher level category of Article\n",
    "            - 'Section': Lower level category of Article\n",
    "            - 'url': URL to data set\n",
    "            - 'Headline': Headline of Article\n",
    "            - 'Description': Short Summary of Article\n",
    "            - 'Keywords': Keywords of Article\n",
    "            - 'Second headline': Second Headline of Article\n",
    "            - 'Article text': Full article text\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned data set.\n",
    "\n",
    "    \"\"\"\n",
    "    if set(data_1.columns) != set(data_2.columns):\n",
    "        msg = \"Both datasets must have the same columns.\"\n",
    "        raise ValueError(msg)\n",
    "    merged_dataset = pd.concat([data_1, data_2], axis=0)\n",
    "    # put this into task\n",
    "    merged_dataset = _drop_columns(merged_dataset)\n",
    "    return _pd_to_dataset(merged_dataset)\n",
    "\n",
    "\n",
    "def _drop_columns(data):\n",
    "    \"\"\"Drop columns from data set.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data set.\n",
    "        columns_to_drop (list): List of columns to drop.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The data set without the dropped columns.\n",
    "\n",
    "    \"\"\"\n",
    "    data = data.drop(columns=data[\"Headline\"])\n",
    "    data = data.dropna()\n",
    "    return data[~data[\"Category\"].isin(data[\"sport\"])]\n",
    "\n",
    "\n",
    "def _pd_to_dataset(data):\n",
    "    data = Dataset.from_pandas(data)\n",
    "    dataset_dict = DatasetDict({\"my_dataset\": data})\n",
    "    return dataset_dict[\"my_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytask.mark.depends_on(\n",
    "    {\n",
    "        \"scripts\": [\"load_data.py\"],\n",
    "    },\n",
    ")\n",
    "@pytask.mark.task\n",
    "@pytask.mark.produces(\n",
    "    BLD / \"python\" / \"data\",\n",
    ")  # / \"cnn-articles-after-basic-cleaning.zip\"\n",
    "def task_load_data(produces):\n",
    "    \"\"\"Clean the data (Python version).\"\"\"\n",
    "    api = authenticate_to_kaggle()\n",
    "    dataset = \"hadasu92/cnn-articles-after-basic-cleaning\"\n",
    "    api.dataset_download_files(dataset)\n",
    "    jo = kaggle.api.dataset_download_files(\n",
    "        dataset,\n",
    "        path=produces,\n",
    "        unzip=True,\n",
    "        quiet=False,\n",
    "    )\n",
    "    with open(produces) as f:\n",
    "        f.write(jo)\n",
    "\n",
    "        # @pytask.mark.depends_on(BLD / \"python\" / \"data\" / \"cnn-articles-after-basic-cleaning.zip\")\n",
    "\n",
    "\n",
    "# @pytask.mark.produces(BLD / \"python\" / \"data\" / \"cnn-articles-after-basic-cleaning.zip\")\n",
    "# def task_unzip(produces):\n",
    "#    with zipfile.ZipFile(\"cnn-articles-after-basic-cleaning.zip\", \"r\") as zip_ref:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = pd.DataFrame(classifier(df[\"val_dataset\"][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, return_dict=True)\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "df_encoded = df.map(tokenize, batched=True, batch_size=None)\n",
    "df_encoded.set_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "df_encoded.set_format(\"torch\")\n",
    "df_encoded = df_encoded.remove_columns(\"classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=model_config,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bis hier hin wirkt gut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 ab hier mal schauen, hat bis train geklappt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 ab hier mal schauen, hat bis train geklappt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "logging_steps = len(df_encoded[\"train_dataset\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    optim=\"adamw_torch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    num_train_epochs=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=df_encoded[\"train_dataset\"],\n",
    "    eval_dataset=df_encoded[\"val_dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded[\"val_dataset\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define your model name\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, return_dict=True)\n",
    "\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_text(example):\n",
    "    return tokenizer(example[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "df_encoded = df.map(tokenize_text, batched=True)\n",
    "df_encoded.set_format(\"pandas\")\n",
    "\n",
    "\n",
    "# Convert labels to integer class indices\n",
    "def convert_labels(dataset):\n",
    "    dataset[\"label\"] = dataset[\"label\"].apply(\n",
    "        lambda x: torch.argmax(torch.tensor(x)).item(),\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "df_encoded[\"train_dataset\"] = convert_labels(df_encoded[\"train_dataset\"])\n",
    "df_encoded[\"val_dataset\"] = convert_labels(df_encoded[\"val_dataset\"])\n",
    "df_encoded[\"test_dataset\"] = convert_labels(df_encoded[\"test_dataset\"])\n",
    "\n",
    "# Convert tokenized text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    ")  # You can adjust the number of features as needed\n",
    "X_train = vectorizer.fit_transform(df_encoded[\"train_dataset\"][\"text\"])\n",
    "X_val = vectorizer.transform(df_encoded[\"val_dataset\"][\"text\"])\n",
    "X_test = vectorizer.transform(df_encoded[\"test_dataset\"][\"text\"])\n",
    "\n",
    "# Create and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    ")  # You can adjust hyperparameters as needed\n",
    "clf.fit(X_train, df_encoded[\"train_dataset\"][\"label\"])\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_preds = clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "val_labels = df_encoded[\"val_dataset\"][\"label\"]\n",
    "val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
    "val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "print(f\"Validation F1 Score: {val_f1}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusatz von den model_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultilabelSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels),\n",
    "                labels.float().view(-1, self.num_labels),\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss, *output)) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv(\"bld/python/data/benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark[\"__index_level_0__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adwaw = pd.read_csv(r\"src\\EN\\data\\seed_42_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adwaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = load_from_disk(\"bld/python/data/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = pd.DataFrame(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_random_entries(large_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"__index_level_0__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_entries(dataframe, num_entries=50, random_state=42):\n",
    "    \"\"\"Select a random set of entries from a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (json): The input DataFrame with 6 columns.\n",
    "        num_entries (int): The number of random entries to select (default is 50).\n",
    "        random_state (int or None): Random seed for reproducibility (default is None).\n",
    "\n",
    "    Returns:\n",
    "        random_entries (pd.DataFrame): A DataFrame containing the randomly selected entries.\n",
    "\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    if num_entries > len(dataframe):\n",
    "        msg = \"Number of entries to select cannot exceed the total number of rows.\"\n",
    "        raise ValueError(\n",
    "            msg,\n",
    "        )\n",
    "\n",
    "    # Use Pandas' sample method to select random entries\n",
    "    random_indices = np.random.choice(\n",
    "        dataframe[\"__index_level_0__\"],\n",
    "        size=num_entries,\n",
    "        replace=False,\n",
    "    )\n",
    "    return dataframe[dataframe[\"__index_level_0__\"].isin(random_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def select_random_entries(dataframe, num_entries=50, random_state=42):\n",
    "    \"\"\"Select a random set of entries from a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (json): The input DataFrame with 6 columns.\n",
    "        num_entries (int): The number of random entries to select (default is 50).\n",
    "        random_state (int or None): Random seed for reproducibility (default is None).\n",
    "\n",
    "    Returns:\n",
    "        random_entries (pd.DataFrame): A DataFrame containing exactly 50 randomly selected entries.\n",
    "\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    if num_entries > len(dataframe):\n",
    "        msg = \"Number of entries to select cannot exceed the total number of rows.\"\n",
    "        raise ValueError(\n",
    "            msg,\n",
    "        )\n",
    "\n",
    "    if len(dataframe) <= num_entries:\n",
    "        # If the DataFrame has fewer or equal rows than num_entries, select all of them\n",
    "        random_entries = dataframe\n",
    "    else:\n",
    "        # Use Pandas' sample method to select num_entries random entries\n",
    "        random_indices = np.random.choice(\n",
    "            dataframe[\"__index_level_0__\"],\n",
    "            size=num_entries,\n",
    "            replace=False,\n",
    "        )\n",
    "        random_entries = dataframe[dataframe[\"__index_level_0__\"].isin(random_indices)]\n",
    "\n",
    "    # If the selected random_entries has fewer than num_entries rows, select more randomly\n",
    "    while len(random_entries) < num_entries:\n",
    "        additional_indices = np.random.choice(\n",
    "            dataframe[\"__index_level_0__\"],\n",
    "            size=num_entries - len(random_entries),\n",
    "            replace=False,\n",
    "        )\n",
    "        additional_entries = dataframe[\n",
    "            dataframe[\"__index_level_0__\"].isin(additional_indices)\n",
    "        ]\n",
    "        random_entries = pd.concat([random_entries, additional_entries])\n",
    "\n",
    "    return random_entries.sample(n=num_entries, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for maybe latler\n",
    "\n",
    "\n",
    "@pytask.mark.depends_on(\n",
    "    {\n",
    "        \"scripts\": [\"clean_data.py\"],\n",
    "        \"data_info\": SRC / \"data_management\" / \"data_info.yaml\",\n",
    "        \"Article_1\": BLD\n",
    "        / \"python\"\n",
    "        / \"data\"\n",
    "        / \"CNN_Articels_clean\"\n",
    "        / \"CNN_Articels_clean.csv\",\n",
    "        \"Article_2\": BLD\n",
    "        / \"python\"\n",
    "        / \"data\"\n",
    "        / \"CNN_Articels_clean_2\"\n",
    "        / \"CNN_Articels_clean.csv\",\n",
    "        \"Seed42_hand_classification\": SRC / \"data\" / \"seed_42_classification.csv\",\n",
    "    },\n",
    ")\n",
    "@pytask.mark.produces(BLD / \"python\" / \"data\" / \"benchmark.csv\")\n",
    "def task_select_data(depends_on, produces):\n",
    "    \"Subset the data to 50 entries and add the hand classification.\"\n",
    "    df_1 = pd.read_csv(depends_on[\"Article_1\"])  # need to delete cache here\n",
    "    df_2 = pd.read_csv(\n",
    "        depends_on[\"Article_2\"],\n",
    "    )\n",
    "    data_info = read_yaml(depends_on[\"data_info\"])\n",
    "    data = clean_data(df_1, df_2, data_info)\n",
    "    data = select_random_entries(data, num_entries=50, random_state=42)\n",
    "\n",
    "    data.to_csv(produces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "conda-lock 2.1.2 requires click>=8.0, but you have click 7.1.2 which is incompatible."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
