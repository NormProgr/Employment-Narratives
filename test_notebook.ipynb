{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Lecture 7 is key to my problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/data/data_clean\")\n",
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"Article text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = (\n",
    "    \"Tiger Woods: Is this the end of his era? - CNN,Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. \",\n",
    "    \"golf, Tiger Woods: Is this the end of his era? - CNN,Is this the end of the Tiger Woods era?,This story was excerpted from the November 23 edition of CNN's Meanwhile in America, the daily email about US politics for global readers. Click here to read past editions and subscribe. (CNN)Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. Woods, who is recuperating from devastating leg injuries from a car crash, told Golf Digest he would have to be more selective about competition from now on. \"\n",
    "    \"I think something that is realistic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(sequence_to_classify, candidate_labels, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasoning for new model\n",
    "\n",
    "https://huggingface.co/valhalla/distilbart-mnli-12-1 has 90% of the facebook/bart-large-mnli model's performance but is way faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/data/data_clean\")\n",
    "model_name = \"facebook/bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_2 = \"valhalla/distilbart-mnli-12-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"valhalla/distilbart-mnli-12-1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16,  # adjust batch size\n",
    "    )\n",
    "\n",
    "\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=True, truncation=True, max_length=42)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "from transformers import AutoTokenizer, AutoModel, , AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"facebook/bart-large-mnli\"\n",
    "    tokenizer = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16, # adjust batch size\n",
    "    )\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function\n",
    "df_encoded = zero_shot_labelling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name_2,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = (\n",
    "    \"Tiger Woods: Is this the end of his era? - CNN,Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. \",\n",
    "    \"golf, Tiger Woods: Is this the end of his era? - CNN,Is this the end of the Tiger Woods era?,This story was excerpted from the November 23 edition of CNN's Meanwhile in America, the daily email about US politics for global readers. Click here to read past editions and subscribe. (CNN)Tiger Woods is the rarest of athletes. At his peak, he transcended his sport. People who couldn't care less about golf watched in their millions on Sunday afternoons to see him roar. So the 15-time major champ's announcement that he is calling time on life as a full-time pro feels like the end of an era. Woods, who is recuperating from devastating leg injuries from a car crash, told Golf Digest he would have to be more selective about competition from now on. \"\n",
    "    \"I think something that is realistic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df_try = df\n",
    "\n",
    "\n",
    "def pd_to_dataset(data):\n",
    "    data = Dataset.from_pandas(data)\n",
    "    dataset_dict = DatasetDict({\"my_dataset\": data})\n",
    "    return dataset_dict[\"my_dataset\"]\n",
    "\n",
    "\n",
    "df_encoded = zero_shot_labelling(df_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(df_encoded[\"Description\"], candidate_labels, tokenizer=_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to speed it up:\n",
    "- Batch size of 8\n",
    "- padding can be reduced to speed up computation\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "delete_strategy = scan_cache_dir().delete_revisions(\n",
    "    \"81fd1d6e7847c99f5862c9fb81387956d99ec7aa\"\n",
    "    \"e2983b237dccf3ab4937c97fa717319a9ca1a96d\",\n",
    "    \"6c0e6080953db56375760c0471a8c5f2929baf11\",\n",
    ")\n",
    "print(\"Will free \" + delete_strategy.expected_freed_size_str)\n",
    "\n",
    "\n",
    "delete_strategy.execute()\n",
    "\n",
    "# Specify the directory you want to clear the cache for\n",
    "cache_directory = \"/path/to/your/cache/directory\"\n",
    "\n",
    "# Use scan_cache_dir to clear the cache in the specified directory\n",
    "scan_cache_dir(cache_directory).clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuer try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "df = load_from_disk(\"bld/python/data/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = zero_shot_labelling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def zero_shot_labelling(data):\n",
    "    model_name = \"valhalla/distilbart-mnli-12-1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=16,  # adjust batch size\n",
    "    )\n",
    "\n",
    "\n",
    "# batch of 8: 47.4, padding = True\n",
    "# batch of 16: 41.3, padding True\n",
    "# batch of 16: 38.4, padding = \"max_length\"\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"Description\"], padding=True, truncation=True, max_length=42)\n",
    "\n",
    "\n",
    "# Call zero_shot_labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"labor supply\", \"labor demand\", \"government intervention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_2 = \"valhalla/distilbart-mnli-12-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name_2,\n",
    "    multi_label=True,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(df[\"Description\"], candidate_labels, tokenizer=_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "df = load_from_disk(\"bld/python/data/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100_entries = df.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = zero_shot_classifier(first_100_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def zero_shot_classifier(data):\n",
    "    \"\"\"Classify the zero-shot data to receive the labels.\"\"\"\n",
    "    data = _zero_shot_labelling(data)\n",
    "    model_name = \"valhalla/distilbart-mnli-12-6\"\n",
    "    labels = [\"labor supply\", \"labor demand\", \"government intervention\"]\n",
    "    classifier = pipeline(  # second last\n",
    "        \"zero-shot-classification\",\n",
    "        model=model_name,\n",
    "        multi_label=True,\n",
    "        device=\"cuda:0\" if torch.cuda.is_available() else None,\n",
    "    )\n",
    "    return classifier(  # last\n",
    "        data[\"Description\"],\n",
    "        labels,\n",
    "        tokenizer=_tokenize,\n",
    "    )\n",
    "\n",
    "\n",
    "def _zero_shot_labelling(data):\n",
    "    \"\"\"Load the model for zero-shot classification and apply on the data.\"\"\"\n",
    "    model_name = \"valhalla/distilbart-mnli-12-6\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return data.map(\n",
    "        lambda batch: _tokenize(batch, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=8,\n",
    "    )\n",
    "\n",
    "\n",
    "def _tokenize(batch, tokenizer):\n",
    "    \"\"\"Define the tokenizer.\"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"Description\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For reading to know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the previous\n",
    "select_random_entries(df, num_entries=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- does the probability of the model suits or should I transform to 0 and 1\n",
    "- test and training separation\n",
    "- model selection\n",
    "- put the head on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "df = load_from_disk(r\"bld\\python\\labelled\\data_labelled_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset_dict_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save_to_disk(\"bld/python/TrainTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "def _split_dataset(df):\n",
    "    # Shuffle the dataset to ensure randomization\n",
    "    df = df.shuffle(seed=42)\n",
    "\n",
    "    # Calculate the split sizes\n",
    "    total_size = len(df)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = int(0.1 * total_size)\n",
    "    total_size - train_size - val_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset = datasets.Dataset.from_dict(df[:train_size])\n",
    "    val_dataset = datasets.Dataset.from_dict(df[train_size : train_size + val_size])\n",
    "    test_dataset = datasets.Dataset.from_dict(df[train_size + val_size :])\n",
    "\n",
    "    # Rename columns if needed\n",
    "    train_dataset = train_dataset.rename_column(\"sequence\", \"text\")\n",
    "    val_dataset = val_dataset.rename_column(\"sequence\", \"text\")\n",
    "    test_dataset = test_dataset.rename_column(\"sequence\", \"text\")\n",
    "\n",
    "    # You may need to specify the 'labels' column name if it's different\n",
    "    # Assuming it's 'labels' in your dataset, rename it to 'label'\n",
    "    train_dataset = train_dataset.rename_column(\"labels\", \"label\")\n",
    "    val_dataset = val_dataset.rename_column(\"labels\", \"label\")\n",
    "    test_dataset = test_dataset.rename_column(\"labels\", \"label\")\n",
    "\n",
    "    return {\n",
    "        \"train_dataset\": train_dataset,\n",
    "        \"val_dataset\": val_dataset,\n",
    "        \"test_dataset\": test_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataset_dict_2(df):\n",
    "    # Split the dataset using the split_dataset function\n",
    "    split_data = _split_dataset(df)\n",
    "\n",
    "    # Create a DatasetDict containing train, validation, and test datasets\n",
    "    return datasets.DatasetDict(split_data)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = Your existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train_dataset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_ckpt,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[\"train_dataset\"].column_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[\"train_dataset\"].column_names\n",
    "cols.remove(\"scores\")\n",
    "df_enc = df.map(tokenize_and_encode, batched=True, remove_columns=cols)\n",
    "df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores and labels are badly named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast label IDs to floats\n",
    "import torch\n",
    "\n",
    "df_enc.set_format(\"torch\")\n",
    "df_enc = df_enc.map(\n",
    "    lambda x: {\"float_labels\": x[\"scores\"].to(torch.float)},\n",
    "    remove_columns=[\"scores\"],\n",
    ").rename_column(\"float_labels\", \"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=1,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\".\", num_train_epochs=1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=df_enc[\"train_dataset\"],\n",
    "    eval_dataset=df_enc[\"val_dataset\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc[\"train_dataset\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input lists to tensors\n",
    "input_ids = torch.tensor(df_enc[\"train_dataset\"][\"input_ids\"])\n",
    "attention_mask = torch.tensor(df_enc[\"train_dataset\"][\"attention_mask\"])\n",
    "\n",
    "# Forward pass through the model to get logits\n",
    "logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(\n",
    "    logits.logits,\n",
    "    scores.float(),\n",
    ")  # Use logits.logits to access the raw logits\n",
    "\n",
    "# Apply a threshold to the logits to determine class predictions (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "predictions = (torch.sigmoid(logits.logits) >= threshold).int()\n",
    "\n",
    "# 'predictions' now contains the predicted classes for each ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=df[\"train_dataset\"],\n",
    "    eval_dataset=df[\"val_dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additionall model/CURRENT ISSUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train_dataset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import DatasetDict\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# Initialize a pre-trained tokenizer and model\n",
    "model_name = \"bert-base-uncased\"  # You can change this to your desired model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "\n",
    "# Assuming df_enc contains the dataset in the correct format\n",
    "# df_enc should look like this:\n",
    "# DatasetDict({\n",
    "#     train_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "#     val_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "#     test_dataset: Dataset({\n",
    "#         features: ['input_ids', 'attention_mask', 'scores'],\n",
    "\n",
    "# Define the loss function for multi-label classification (e.g., BCEWithLogitsLoss)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Convert text data to input tensors using the tokenizer\n",
    "df[\"train_dataset\"] = tokenizer(\n",
    "    df[\"train_dataset\"][\"text\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "df[\"val_dataset\"] = tokenizer(\n",
    "    df[\"val_dataset\"][\"text\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# Forward pass through the model to get logits\n",
    "input_ids = df[\"train_dataset\"][\"input_ids\"]\n",
    "attention_mask = df[\"train_dataset\"][\"attention_mask\"]\n",
    "logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Assuming 'scores' is already in the correct format\n",
    "scores = torch.tensor(df[\"train_dataset\"][\"scores\"], dtype=torch.float32)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(logits.logits, scores)\n",
    "\n",
    "# Define your training arguments and trainer and train the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,  # Adjust as needed\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,  # Adjust as needed\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=None,  # You can specify a data collator if needed\n",
    "    train_dataset=df_enc[\"train_dataset\"],  # Use your train_dataset here\n",
    "    eval_dataset=df_enc[\"val_dataset\"],  # Use your val_dataset here\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "labels = df[\"train_dataset\"][\"label\"]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"bert-base-cased\"\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(df[\"train_dataset\"][\"scores\"][0]),\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Function to preprocess the dataset and return it in the required format\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the text and encode it into input features\n",
    "    inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Convert scores to a tensor (assuming scores are already in the correct format)\n",
    "    scores = torch.tensor(examples[\"scores\"], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"labels\": scores,\n",
    "    }\n",
    "\n",
    "\n",
    "# Preprocess the datasets\n",
    "train_dataset = df[\"train_dataset\"].map(preprocess_function)\n",
    "val_dataset = df[\"val_dataset\"].map(preprocess_function)\n",
    "test_dataset = df[\"test_dataset\"].map(preprocess_function)\n",
    "\n",
    "# Define your training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, p.label_ids\n",
    "    predictions = (predictions > 0).astype(int)  # Convert logits to binary predictions\n",
    "    f1 = f1_score(labels, predictions, average=\"micro\")\n",
    "    precision = precision_score(labels, predictions, average=\"micro\")\n",
    "    recall = recall_score(labels, predictions, average=\"micro\")\n",
    "    return {\"f1_micro\": f1, \"precision_micro\": precision, \"recall_micro\": recall}\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df[\"train_dataset\"].select_columns([\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess because values are apparently string and not int\n",
    "\n",
    "model_output = pd.DataFrame(classifier(df[\"val_dataset\"][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "\n",
    "def tokenize_data(df):\n",
    "    return tokenizer(\n",
    "        df[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "df_encoded = df.map(tokenize, batched=True, batch_size=None)\n",
    "df_encoded.set_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "df_encoded.set_format(\"torch\")\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 6\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\", num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=df_encoded[\"train_dataset\"],\n",
    "    eval_dataset=df_encoded[\"val_dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def authenticate_to_kaggle():\n",
    "    \"\"\"Authenticate to Kaggle.\"\"\"\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_load_data_python(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"bld/python/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "\n",
    "def task_load_data_python(path):\n",
    "    \"\"\"Clean the data (Python version).\n",
    "\n",
    "    Download needs up to 5 minutes. Is this due to internet or coding issue?\n",
    "\n",
    "    \"\"\"\n",
    "    api = authenticate_to_kaggle()\n",
    "    dataset = \"hadasu92/cnn-articles-after-basic-cleaning\"\n",
    "    api.dataset_download_files(dataset)\n",
    "    with zipfile.ZipFile(\"cnn-articles-after-basic-cleaning.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
