{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning\n",
    "There are two ways we can implement multi-label classification:\n",
    "\n",
    "- Creating a custom BERT model that overrides the forward method\n",
    "- Creating a custom Trainer that overrides the compute_loss method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error could be here\n",
    "cols = ds[\"train_dataset\"].column_names\n",
    "cols.remove(\"label\")\n",
    "ds_enc = ds.map(tokenize_and_encode, batched=True, remove_columns=cols)\n",
    "ds_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        inputs.pop(\"label\")  # maybe here error\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels),\n",
    "            labels.float().view(-1, self.model.config.num_labels),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=3).to(\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not important first\n",
    "def accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=True):\n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid:\n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred > thresh) == y_true.bool()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not important first\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {\"accuracy_thresh\": accuracy_thresh(predictions, label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"jigsaw\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer = MultilabelTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_enc[\"train_dataset\"],\n",
    "    eval_dataset=ds_enc[\"val_dataset\"],\n",
    "    compute_metrics=compute_metrics,  # not important for problem\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Error MEssage\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "Cell In[30], line 1\n",
    "----> 1 multi_trainer.evaluate()\n",
    "\n",
    "File c:\\Users\\norma\\.conda\\envs\\EN\\Lib\\site-packages\\transformers\\trainer.py:2934, in Trainer.evaluate(self, eval_dataset, ignore_keys, metric_key_prefix)\n",
    "   2931 start_time = time.time()\n",
    "   2933 eval_loop = self.prediction_loop if self.args.use_legacy_prediction_loop else self.evaluation_loop\n",
    "-> 2934 output = eval_loop(\n",
    "   2935     eval_dataloader,\n",
    "   2936     description=\"Evaluation\",\n",
    "   2937     # No point gathering the predictions if there are no metrics, otherwise we defer to\n",
    "   2938     # self.args.prediction_loss_only\n",
    "   2939     prediction_loss_only=True if self.compute_metrics is None else None,\n",
    "   2940     ignore_keys=ignore_keys,\n",
    "   2941     metric_key_prefix=metric_key_prefix,\n",
    "   2942 )\n",
    "   2944 total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
    "   2945 if f\"{metric_key_prefix}_jit_compilation_time\" in output.metrics:\n",
    "\n",
    "File c:\\Users\\norma\\.conda\\envs\\EN\\Lib\\site-packages\\transformers\\trainer.py:3123, in Trainer.evaluation_loop(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\n",
    "   3120         batch_size = observed_batch_size\n",
    "   3122 # Prediction step\n",
    "-> 3123 loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
    "   3124 inputs_decode = self._prepare_input(inputs[\"input_ids\"]) if args.include_inputs_for_metrics else None\n",
    "...\n",
    "--> 241     return self.data[item]\n",
    "    242 elif self._encodings is not None:\n",
    "    243     return self._encodings[item]\n",
    "\n",
    "KeyError: 'label'\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
