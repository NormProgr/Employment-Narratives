{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'eval_loss': 0.6905103921890259: This is the evaluation loss. It represents a measure of how well the model's predictions match the true labels in the validation dataset. Lower values indicate better performance.\n",
    "\n",
    "- 'eval_accuracy_thresh': 0.46666666865348816: This is the accuracy threshold. It indicates the threshold value used for binary classification. Predictions with a probability greater than or equal to this threshold are classified as the positive class, and those below it are classified as the negative class. In this case, the threshold is set to approximately 0.467.\n",
    "\n",
    "- 'eval_runtime': 0.3652: This is the time it took to perform the evaluation in seconds. It measures how long it took to evaluate the model on the validation dataset.\n",
    "\n",
    "- 'eval_samples_per_second': 27.384: This is the number of validation samples processed per second during evaluation. It indicates the evaluation speed.\n",
    "\n",
    "- 'eval_steps_per_second': 5.477: This is the number of evaluation steps (batches) processed per second. In some cases, evaluation is performed in batches to make it more memory-efficient and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"bld/python/TrainTest/TrainTest_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train_dataset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_translation(dataset):\n",
    "    \"\"\"Translate the labels to 0 and 1.\"\"\"\n",
    "    return dataset.map(\n",
    "        lambda example: {\"label\": [1 if x > 0.5 else 0 for x in example[\"label\"]]},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0/1 change\n",
    "# Argument for this: 0/1 is harder on the model being able to predict the extreme cases. A continuous approach would be better on the not so hard cases but this seems less interesting, also I assume my zero-shot to be true for my model\n",
    "# Assuming you have a DatasetDict named 'ds'\n",
    "ds[\"train_dataset\"] = ds[\"train_dataset\"].map(\n",
    "    lambda example: {\"label\": [1 if x > 0.5 else 0 for x in example[\"label\"]]},\n",
    ")\n",
    "ds[\"val_dataset\"] = ds[\"val_dataset\"].map(\n",
    "    lambda example: {\"label\": [1 if x > 0.5 else 0 for x in example[\"label\"]]},\n",
    ")\n",
    "ds[\"test_dataset\"] = ds[\"test_dataset\"].map(\n",
    "    lambda example: {\"label\": [1 if x > 0.5 else 0 for x in example[\"label\"]]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning\n",
    "There are two ways we can implement multi-label classification:\n",
    "\n",
    "- Creating a custom BERT model that overrides the forward method\n",
    "- Creating a custom Trainer that overrides the compute_loss method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative tokenizer\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"sequence\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "ds_encoded = ds.map(tokenize, batched=True, batch_size=None)\n",
    "ds_encoded.set_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    ")\n",
    "ds_encoded.set_format(\"torch\")\n",
    "ds_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my resource: https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a model (Task 1 Exercise 9)\n",
    "class BertForMultilabelSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels),\n",
    "                labels.float().view(-1, self.num_labels),\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss, *output)) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3\n",
    "model = BertForMultilabelSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=num_labels,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=True):\n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid:\n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred > thresh) == y_true.bool()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {\"accuracy_thresh\": accuracy_thresh(predictions, labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual part resumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_encoded[\"train_dataset\"],  # this could also be an error\n",
    "    eval_dataset=ds_encoded[\"val_dataset\"],  # this could also be an error\n",
    "    compute_metrics=compute_metrics,  # not important for problem\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_encoded[\"train_dataset\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not important addiditon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels),\n",
    "            labels.float().view(-1, self.model.config.num_labels),\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=num_labels,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer = MultilabelTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_encoded[\"train_dataset\"],  # this could also be an error\n",
    "    eval_dataset=ds_encoded[\"val_dataset\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the last hidden stat for pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_states(batch, model):\n",
    "    input_ids = torch.tensor(batch[\"input_ids\"])\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        lhs = output.last_hidden_state.cpu().numpy()\n",
    "\n",
    "    valid = np.array(batch[\"attention_mask\"]).astype(bool)\n",
    "\n",
    "    batch_size, n_tokens, hidden_dim = lhs.shape\n",
    "    valid = valid.reshape(batch_size, n_tokens, 1).repeat(hidden_dim, axis=-1)\n",
    "\n",
    "    masked_mean = np.ma.array(lhs, mask=~valid).mean(axis=1).data\n",
    "\n",
    "    batch[\"hidden_state\"] = masked_mean\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_encoded[\"train_dataset\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_states(batch, model_ckpt)  # error here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_states = emotions_encoded.map(\n",
    "    extract_states,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    fn_kwargs={\"model\": model},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(last_states[\"train_dataset\"][\"hidden_state\"])\n",
    "X_test = np.array(last_states[\"test\"][\"hidden_state\"])\n",
    "y_train = np.array(last_states[\"train\"][\"label\"])\n",
    "y_test = np.array(last_states[\"test\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_text = \"I am glad the class is almost over.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tokenizer.encode(custom_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(input_tensor).logits.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = scipy.special.softmax(logits.flatten())\n",
    "probs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
